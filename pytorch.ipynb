{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "training = (\n",
    "    \"http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\",\n",
    "    \"http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\"\n",
    ")\n",
    "\n",
    "testing = (\n",
    "    \"http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\",\n",
    "    \"http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\"\n",
    ")\n",
    "\n",
    "def dl_mnist(ds, prefix):\n",
    "    img_url, lab_url = ds\n",
    "    print(f\"Downloading {prefix}\")\n",
    "    urllib.request.urlretrieve(img_url, f'./{prefix}-img')\n",
    "    urllib.request.urlretrieve(lab_url, f'./{prefix}-lab')\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_mnist(training, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import gzip\n",
    "\n",
    "class MnistDataset(Dataset):\n",
    "    def __init__(self, imgfile, labelfile, transform=None):\n",
    "        self.imgfile = imgfile\n",
    "        self.labelfile = labelfile\n",
    "        self.images, self.labels = self.read_dataset(imgfile, labelfile)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        sample = {'image': self.images[idx], 'label': self.labels[idx]}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "\n",
    "    def read_dataset(self, imgname, labname):\n",
    "        import struct\n",
    "        import gzip\n",
    "        X = []\n",
    "        y = []\n",
    "        with gzip.open(imgname, \"rb\") as img, gzip.open(labname, \"rb\") as labs:\n",
    "            img_header = struct.unpack(\">4i\", img.read(16))\n",
    "            lab_header = struct.unpack(\">2i\", labs.read(8))\n",
    "\n",
    "            img_size = img_header[2] * img_header[3]\n",
    "\n",
    "            for i in range(img_header[1]):\n",
    "                image = struct.unpack(f\"{img_size}B\", img.read(img_size))\n",
    "                label = struct.unpack(\"B\", labs.read(1))\n",
    "                image = np.array(image).reshape((28, 28))\n",
    "                X.append(image)\n",
    "                y.append(label[0])\n",
    "            X = np.array(X, dtype=\"float32\")\n",
    "        return X, np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class normalize(object):\n",
    "    \"\"\"Rescale values between 0 and 1\"\"\"\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        \n",
    "        return {'image': image / 255, 'label': label}\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'label': label}\n",
    "    \n",
    "compose = transforms.Compose([ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data(x):\n",
    "    img = x['image'].numpy()\n",
    "    plt.imshow(x['image'], cmap='Greys')\n",
    "    plt.xlabel(f\"Label: {x['label'].item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = MnistDataset(\"train-img\", \"train-lab\", transform=compose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(ds[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(ds, batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_mnist(testing, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = MnistDataset(\"test-img\", 'test-lab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test, shuffle=True, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 120)\n",
    "        self.fc2 = nn.Linear(120, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = F.softmax(self.fc2(x), dim=1)\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloader):\n",
    "            images, labels = data['image'], data['label']\n",
    "            out = net(images)\n",
    "            out = torch.argmax(out, dim=1)\n",
    "            total += labels.shape[0]\n",
    "            correct += (out == labels).sum().item()\n",
    "    print(\"Training accuracy:\", correct / total)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "\n",
    "running_loss = 0.0\n",
    "mlp_accuracy = []\n",
    "for e in range(epoch):\n",
    "    for i, data in enumerate(dataloader):\n",
    "        images, labels = data['image'], data['label']\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = net(images)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 0:\n",
    "            #print('[%d, %5d] loss: %.3f' %\n",
    "                  #(e + 1, i + 1, running_loss / 1000))\n",
    "            #running_loss = 0.0\n",
    "            mlp_accuracy.append(accuracy(test_dataloader))\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ds[112]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.forward(data['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv = nn.Conv2d(1, 3, 3)\n",
    "        self.fc = nn.Linear(3 * 28 * 28, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv(x))\n",
    "        x = x.view(-1, 3 * 28 * 28)\n",
    "        x = self.fc(conv)\n",
    "        \n",
    "cnn = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "\n",
    "running_loss = 0.0\n",
    "cnn_accuracy = []\n",
    "for e in range(epoch):\n",
    "    for i, data in enumerate(dataloader):\n",
    "        images, labels = data['image'], data['label']\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = net(images)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 0:\n",
    "            #print('[%d, %5d] loss: %.3f' %\n",
    "                  #(e + 1, i + 1, running_loss / 1000))\n",
    "            #running_loss = 0.0\n",
    "            cnn_accuracy.append(accuracy(test_dataloader))\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import show, figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(tools=\"wheel_zoom,pan,hover,reset\")\n",
    "p.line(np.arange(len(mlp_accuracy)), mlp_accuracy, line_color=\"blue\", line_width=3, legend=\"MLP\")\n",
    "p.line(np.arange(len(cnn_accuracy)), cnn_accuracy, line_color=\"red\", line_width=3, legend=\"CNN\")\n",
    "p.legend.location=\"top_left\"\n",
    "p.legend.click_policy=\"hide\"\n",
    "p.yaxis.axis_label=\"Accuracy (%)\"\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
