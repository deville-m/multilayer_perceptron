{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NeuralNet import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def fetch(f):\n",
    "    df = pd.read_csv(f, header=None, index_col=0)\n",
    "    labels = df.pop(1).eq('M').mul(1)\n",
    "    mean = df.mean()\n",
    "    std = df.std()\n",
    "    data = (df - mean) / std\n",
    "    X, y = data.values.astype(float), labels.values.astype(int)\n",
    "    y = y.reshape(-1, 1)\n",
    "    y = np.array([[0, 1] if x else [1, 0] for x in y])\n",
    "    return X, y, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, mean, std = fetch(\"data_training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.permutation(X.shape[0])\n",
    "X, y = X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X).float()\n",
    "y = torch.from_numpy(y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(30, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        self.fc3 = nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=30, out_features=20, bias=True)\n",
      "  (fc2): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (fc3): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.randn(4, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6044, 0.3956],\n",
       "        [0.6090, 0.3910],\n",
       "        [0.6092, 0.3908],\n",
       "        [0.6096, 0.3904]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.forward(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 -- loss: 0.6620203256607056\n",
      "Epoch 1 -- loss: 0.6615859270095825\n",
      "Epoch 2 -- loss: 0.661237895488739\n",
      "Epoch 3 -- loss: 0.6609494090080261\n",
      "Epoch 4 -- loss: 0.6607024073600769\n",
      "Epoch 5 -- loss: 0.6604841351509094\n",
      "Epoch 6 -- loss: 0.6602857112884521\n",
      "Epoch 7 -- loss: 0.660101056098938\n",
      "Epoch 8 -- loss: 0.6599260568618774\n",
      "Epoch 9 -- loss: 0.659757673740387\n",
      "Epoch 10 -- loss: 0.6595937013626099\n",
      "Epoch 11 -- loss: 0.6594329476356506\n",
      "Epoch 12 -- loss: 0.6592741012573242\n",
      "Epoch 13 -- loss: 0.6591166257858276\n",
      "Epoch 14 -- loss: 0.6589599847793579\n",
      "Epoch 15 -- loss: 0.6588036417961121\n",
      "Epoch 16 -- loss: 0.6586474776268005\n",
      "Epoch 17 -- loss: 0.6584910750389099\n",
      "Epoch 18 -- loss: 0.658334493637085\n",
      "Epoch 19 -- loss: 0.658177375793457\n",
      "Epoch 20 -- loss: 0.6580197215080261\n",
      "Epoch 21 -- loss: 0.6578614711761475\n",
      "Epoch 22 -- loss: 0.6577025651931763\n",
      "Epoch 23 -- loss: 0.6575426459312439\n",
      "Epoch 24 -- loss: 0.6573819518089294\n",
      "Epoch 25 -- loss: 0.6572202444076538\n",
      "Epoch 26 -- loss: 0.657057523727417\n",
      "Epoch 27 -- loss: 0.6568937301635742\n",
      "Epoch 28 -- loss: 0.6567288041114807\n",
      "Epoch 29 -- loss: 0.6565624475479126\n",
      "Epoch 30 -- loss: 0.656394898891449\n",
      "Epoch 31 -- loss: 0.6562259197235107\n",
      "Epoch 32 -- loss: 0.6560555100440979\n",
      "Epoch 33 -- loss: 0.6558836698532104\n",
      "Epoch 34 -- loss: 0.6557100415229797\n",
      "Epoch 35 -- loss: 0.6555348634719849\n",
      "Epoch 36 -- loss: 0.6553578972816467\n",
      "Epoch 37 -- loss: 0.6551791429519653\n",
      "Epoch 38 -- loss: 0.6549984812736511\n",
      "Epoch 39 -- loss: 0.6548159718513489\n",
      "Epoch 40 -- loss: 0.6546312570571899\n",
      "Epoch 41 -- loss: 0.6544445157051086\n",
      "Epoch 42 -- loss: 0.6542555689811707\n",
      "Epoch 43 -- loss: 0.6540642976760864\n",
      "Epoch 44 -- loss: 0.653870701789856\n",
      "Epoch 45 -- loss: 0.6536746025085449\n",
      "Epoch 46 -- loss: 0.6534760594367981\n",
      "Epoch 47 -- loss: 0.6532748341560364\n",
      "Epoch 48 -- loss: 0.6530708074569702\n",
      "Epoch 49 -- loss: 0.6528640389442444\n",
      "Epoch 50 -- loss: 0.6526545286178589\n",
      "Epoch 51 -- loss: 0.6524417996406555\n",
      "Epoch 52 -- loss: 0.6522260904312134\n",
      "Epoch 53 -- loss: 0.6520072817802429\n",
      "Epoch 54 -- loss: 0.6517850756645203\n",
      "Epoch 55 -- loss: 0.6515595316886902\n",
      "Epoch 56 -- loss: 0.6513304710388184\n",
      "Epoch 57 -- loss: 0.6510978937149048\n",
      "Epoch 58 -- loss: 0.6508614420890808\n",
      "Epoch 59 -- loss: 0.6506213545799255\n",
      "Epoch 60 -- loss: 0.6503773331642151\n",
      "Epoch 61 -- loss: 0.6501291990280151\n",
      "Epoch 62 -- loss: 0.6498768925666809\n",
      "Epoch 63 -- loss: 0.6496202945709229\n",
      "Epoch 64 -- loss: 0.649359405040741\n",
      "Epoch 65 -- loss: 0.6490939259529114\n",
      "Epoch 66 -- loss: 0.6488237977027893\n",
      "Epoch 67 -- loss: 0.6485488414764404\n",
      "Epoch 68 -- loss: 0.6482690572738647\n",
      "Epoch 69 -- loss: 0.6479840278625488\n",
      "Epoch 70 -- loss: 0.6476939916610718\n",
      "Epoch 71 -- loss: 0.6473985314369202\n",
      "Epoch 72 -- loss: 0.6470975875854492\n",
      "Epoch 73 -- loss: 0.6467909812927246\n",
      "Epoch 74 -- loss: 0.6464785933494568\n",
      "Epoch 75 -- loss: 0.6461602449417114\n",
      "Epoch 76 -- loss: 0.6458356976509094\n",
      "Epoch 77 -- loss: 0.6455049514770508\n",
      "Epoch 78 -- loss: 0.6451677680015564\n",
      "Epoch 79 -- loss: 0.6448238492012024\n",
      "Epoch 80 -- loss: 0.644473135471344\n",
      "Epoch 81 -- loss: 0.6441155076026917\n",
      "Epoch 82 -- loss: 0.6437506675720215\n",
      "Epoch 83 -- loss: 0.6433784365653992\n",
      "Epoch 84 -- loss: 0.6429986357688904\n",
      "Epoch 85 -- loss: 0.6426110863685608\n",
      "Epoch 86 -- loss: 0.6422155499458313\n",
      "Epoch 87 -- loss: 0.6418118476867676\n",
      "Epoch 88 -- loss: 0.6413996815681458\n",
      "Epoch 89 -- loss: 0.6409788727760315\n",
      "Epoch 90 -- loss: 0.6405492424964905\n",
      "Epoch 91 -- loss: 0.6401105523109436\n",
      "Epoch 92 -- loss: 0.6396624445915222\n",
      "Epoch 93 -- loss: 0.6392049193382263\n",
      "Epoch 94 -- loss: 0.6387374997138977\n",
      "Epoch 95 -- loss: 0.6382599472999573\n",
      "Epoch 96 -- loss: 0.6377720832824707\n",
      "Epoch 97 -- loss: 0.6372736692428589\n",
      "Epoch 98 -- loss: 0.6367642879486084\n",
      "Epoch 99 -- loss: 0.6362437009811401\n",
      "Epoch 100 -- loss: 0.6357117295265198\n",
      "Epoch 101 -- loss: 0.6351679563522339\n",
      "Epoch 102 -- loss: 0.6346122026443481\n",
      "Epoch 103 -- loss: 0.6340439915657043\n",
      "Epoch 104 -- loss: 0.6334630846977234\n",
      "Epoch 105 -- loss: 0.6328692436218262\n",
      "Epoch 106 -- loss: 0.6322619915008545\n",
      "Epoch 107 -- loss: 0.6316410303115845\n",
      "Epoch 108 -- loss: 0.631006121635437\n",
      "Epoch 109 -- loss: 0.6303566694259644\n",
      "Epoch 110 -- loss: 0.629692554473877\n",
      "Epoch 111 -- loss: 0.6290132403373718\n",
      "Epoch 112 -- loss: 0.6283184289932251\n",
      "Epoch 113 -- loss: 0.6276077628135681\n",
      "Epoch 114 -- loss: 0.6268807053565979\n",
      "Epoch 115 -- loss: 0.6261369585990906\n",
      "Epoch 116 -- loss: 0.6253759860992432\n",
      "Epoch 117 -- loss: 0.6245975494384766\n",
      "Epoch 118 -- loss: 0.6238011121749878\n",
      "Epoch 119 -- loss: 0.6229861378669739\n",
      "Epoch 120 -- loss: 0.6221522092819214\n",
      "Epoch 121 -- loss: 0.6212990283966064\n",
      "Epoch 122 -- loss: 0.6204259395599365\n",
      "Epoch 123 -- loss: 0.619532585144043\n",
      "Epoch 124 -- loss: 0.618618369102478\n",
      "Epoch 125 -- loss: 0.617682933807373\n",
      "Epoch 126 -- loss: 0.616725504398346\n",
      "Epoch 127 -- loss: 0.6157457828521729\n",
      "Epoch 128 -- loss: 0.6147432327270508\n",
      "Epoch 129 -- loss: 0.6137171983718872\n",
      "Epoch 130 -- loss: 0.6126673221588135\n",
      "Epoch 131 -- loss: 0.6115929484367371\n",
      "Epoch 132 -- loss: 0.6104933619499207\n",
      "Epoch 133 -- loss: 0.6093681454658508\n",
      "Epoch 134 -- loss: 0.6082167625427246\n",
      "Epoch 135 -- loss: 0.6070384979248047\n",
      "Epoch 136 -- loss: 0.6058330535888672\n",
      "Epoch 137 -- loss: 0.6045994162559509\n",
      "Epoch 138 -- loss: 0.6033372282981873\n",
      "Epoch 139 -- loss: 0.6020458340644836\n",
      "Epoch 140 -- loss: 0.6007245779037476\n",
      "Epoch 141 -- loss: 0.5993728637695312\n",
      "Epoch 142 -- loss: 0.5979902148246765\n",
      "Epoch 143 -- loss: 0.5965756773948669\n",
      "Epoch 144 -- loss: 0.5951289534568787\n",
      "Epoch 145 -- loss: 0.5936492085456848\n",
      "Epoch 146 -- loss: 0.5921358466148376\n",
      "Epoch 147 -- loss: 0.5905882716178894\n",
      "Epoch 148 -- loss: 0.5890058279037476\n",
      "Epoch 149 -- loss: 0.5873879790306091\n",
      "Epoch 150 -- loss: 0.5857340097427368\n",
      "Epoch 151 -- loss: 0.5840433239936829\n",
      "Epoch 152 -- loss: 0.58231520652771\n",
      "Epoch 153 -- loss: 0.5805492401123047\n",
      "Epoch 154 -- loss: 0.578744649887085\n",
      "Epoch 155 -- loss: 0.5769010186195374\n",
      "Epoch 156 -- loss: 0.5750176906585693\n",
      "Epoch 157 -- loss: 0.5730941295623779\n",
      "Epoch 158 -- loss: 0.5711297392845154\n",
      "Epoch 159 -- loss: 0.5691241025924683\n",
      "Epoch 160 -- loss: 0.5670766234397888\n",
      "Epoch 161 -- loss: 0.5649868845939636\n",
      "Epoch 162 -- loss: 0.5628544092178345\n",
      "Epoch 163 -- loss: 0.5606787204742432\n",
      "Epoch 164 -- loss: 0.5584595799446106\n",
      "Epoch 165 -- loss: 0.556196391582489\n",
      "Epoch 166 -- loss: 0.5538889765739441\n",
      "Epoch 167 -- loss: 0.5515369772911072\n",
      "Epoch 168 -- loss: 0.549140214920044\n",
      "Epoch 169 -- loss: 0.5466983914375305\n",
      "Epoch 170 -- loss: 0.5442112684249878\n",
      "Epoch 171 -- loss: 0.5416789650917053\n",
      "Epoch 172 -- loss: 0.5391011238098145\n",
      "Epoch 173 -- loss: 0.53647780418396\n",
      "Epoch 174 -- loss: 0.5338091254234314\n",
      "Epoch 175 -- loss: 0.531095027923584\n",
      "Epoch 176 -- loss: 0.5283358097076416\n",
      "Epoch 177 -- loss: 0.5255315899848938\n",
      "Epoch 178 -- loss: 0.5226824879646301\n",
      "Epoch 179 -- loss: 0.5197890400886536\n",
      "Epoch 180 -- loss: 0.516851544380188\n",
      "Epoch 181 -- loss: 0.5138705372810364\n",
      "Epoch 182 -- loss: 0.5108462572097778\n",
      "Epoch 183 -- loss: 0.5077797174453735\n",
      "Epoch 184 -- loss: 0.5046712756156921\n",
      "Epoch 185 -- loss: 0.5015218257904053\n",
      "Epoch 186 -- loss: 0.49833205342292786\n",
      "Epoch 187 -- loss: 0.4951028823852539\n",
      "Epoch 188 -- loss: 0.49183544516563416\n",
      "Epoch 189 -- loss: 0.48853057622909546\n",
      "Epoch 190 -- loss: 0.4851894676685333\n",
      "Epoch 191 -- loss: 0.4818131625652313\n",
      "Epoch 192 -- loss: 0.4784030616283417\n",
      "Epoch 193 -- loss: 0.4749603569507599\n",
      "Epoch 194 -- loss: 0.47148650884628296\n",
      "Epoch 195 -- loss: 0.4679829478263855\n",
      "Epoch 196 -- loss: 0.4644511640071869\n",
      "Epoch 197 -- loss: 0.4608926773071289\n",
      "Epoch 198 -- loss: 0.45730918645858765\n",
      "Epoch 199 -- loss: 0.4537023603916168\n",
      "Epoch 200 -- loss: 0.45007383823394775\n",
      "Epoch 201 -- loss: 0.4464254379272461\n",
      "Epoch 202 -- loss: 0.4427589476108551\n",
      "Epoch 203 -- loss: 0.4390762746334076\n",
      "Epoch 204 -- loss: 0.4353792071342468\n",
      "Epoch 205 -- loss: 0.4316696524620056\n",
      "Epoch 206 -- loss: 0.42794960737228394\n",
      "Epoch 207 -- loss: 0.4242209196090698\n",
      "Epoch 208 -- loss: 0.42048561573028564\n",
      "Epoch 209 -- loss: 0.41674569249153137\n",
      "Epoch 210 -- loss: 0.41300302743911743\n",
      "Epoch 211 -- loss: 0.409259557723999\n",
      "Epoch 212 -- loss: 0.4055172801017761\n",
      "Epoch 213 -- loss: 0.4017781615257263\n",
      "Epoch 214 -- loss: 0.3980441093444824\n",
      "Epoch 215 -- loss: 0.3943168520927429\n",
      "Epoch 216 -- loss: 0.39059847593307495\n",
      "Epoch 217 -- loss: 0.3868906795978546\n",
      "Epoch 218 -- loss: 0.38319528102874756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 219 -- loss: 0.37951406836509705\n",
      "Epoch 220 -- loss: 0.3758487105369568\n",
      "Epoch 221 -- loss: 0.3722008764743805\n",
      "Epoch 222 -- loss: 0.3685721457004547\n",
      "Epoch 223 -- loss: 0.364964097738266\n",
      "Epoch 224 -- loss: 0.3613782227039337\n",
      "Epoch 225 -- loss: 0.3578159213066101\n",
      "Epoch 226 -- loss: 0.35427868366241455\n",
      "Epoch 227 -- loss: 0.35076767206192017\n",
      "Epoch 228 -- loss: 0.34728407859802246\n",
      "Epoch 229 -- loss: 0.34382927417755127\n",
      "Epoch 230 -- loss: 0.3404042422771454\n",
      "Epoch 231 -- loss: 0.33701008558273315\n",
      "Epoch 232 -- loss: 0.3336477279663086\n",
      "Epoch 233 -- loss: 0.3303180932998657\n",
      "Epoch 234 -- loss: 0.3270220160484314\n",
      "Epoch 235 -- loss: 0.3237602710723877\n",
      "Epoch 236 -- loss: 0.3205336034297943\n",
      "Epoch 237 -- loss: 0.317342609167099\n",
      "Epoch 238 -- loss: 0.3141878545284271\n",
      "Epoch 239 -- loss: 0.31106993556022644\n",
      "Epoch 240 -- loss: 0.3079891800880432\n",
      "Epoch 241 -- loss: 0.30494606494903564\n",
      "Epoch 242 -- loss: 0.3019409477710724\n",
      "Epoch 243 -- loss: 0.29897406697273254\n",
      "Epoch 244 -- loss: 0.2960456907749176\n",
      "Epoch 245 -- loss: 0.2931559383869171\n",
      "Epoch 246 -- loss: 0.2903049886226654\n",
      "Epoch 247 -- loss: 0.28749287128448486\n",
      "Epoch 248 -- loss: 0.28471967577934265\n",
      "Epoch 249 -- loss: 0.2819853127002716\n",
      "Epoch 250 -- loss: 0.2792898416519165\n",
      "Epoch 251 -- loss: 0.276633083820343\n",
      "Epoch 252 -- loss: 0.274014949798584\n",
      "Epoch 253 -- loss: 0.27143529057502747\n",
      "Epoch 254 -- loss: 0.26889392733573914\n",
      "Epoch 255 -- loss: 0.2663905918598175\n",
      "Epoch 256 -- loss: 0.26392504572868347\n",
      "Epoch 257 -- loss: 0.26149702072143555\n",
      "Epoch 258 -- loss: 0.25910624861717224\n",
      "Epoch 259 -- loss: 0.2567523419857025\n",
      "Epoch 260 -- loss: 0.2544350326061249\n",
      "Epoch 261 -- loss: 0.2521538734436035\n",
      "Epoch 262 -- loss: 0.24990855157375336\n",
      "Epoch 263 -- loss: 0.24769863486289978\n",
      "Epoch 264 -- loss: 0.24552379548549652\n",
      "Epoch 265 -- loss: 0.243383526802063\n",
      "Epoch 266 -- loss: 0.24127744138240814\n",
      "Epoch 267 -- loss: 0.23920506238937378\n",
      "Epoch 268 -- loss: 0.23716598749160767\n",
      "Epoch 269 -- loss: 0.23515969514846802\n",
      "Epoch 270 -- loss: 0.2331857830286026\n",
      "Epoch 271 -- loss: 0.2312437891960144\n",
      "Epoch 272 -- loss: 0.22933320701122284\n",
      "Epoch 273 -- loss: 0.2274535894393921\n",
      "Epoch 274 -- loss: 0.22560442984104156\n",
      "Epoch 275 -- loss: 0.22378532588481903\n",
      "Epoch 276 -- loss: 0.22199569642543793\n",
      "Epoch 277 -- loss: 0.22023513913154602\n",
      "Epoch 278 -- loss: 0.2185031622648239\n",
      "Epoch 279 -- loss: 0.2167992889881134\n",
      "Epoch 280 -- loss: 0.21512305736541748\n",
      "Epoch 281 -- loss: 0.21347397565841675\n",
      "Epoch 282 -- loss: 0.2118515968322754\n",
      "Epoch 283 -- loss: 0.2102554589509964\n",
      "Epoch 284 -- loss: 0.20868507027626038\n",
      "Epoch 285 -- loss: 0.20714005827903748\n",
      "Epoch 286 -- loss: 0.20561987161636353\n",
      "Epoch 287 -- loss: 0.2041241079568863\n",
      "Epoch 288 -- loss: 0.20265240967273712\n",
      "Epoch 289 -- loss: 0.20120419561862946\n",
      "Epoch 290 -- loss: 0.19977913796901703\n",
      "Epoch 291 -- loss: 0.19837680459022522\n",
      "Epoch 292 -- loss: 0.19699671864509583\n",
      "Epoch 293 -- loss: 0.1956385225057602\n",
      "Epoch 294 -- loss: 0.1943018138408661\n",
      "Epoch 295 -- loss: 0.19298619031906128\n",
      "Epoch 296 -- loss: 0.19169123470783234\n",
      "Epoch 297 -- loss: 0.19041657447814941\n",
      "Epoch 298 -- loss: 0.18916185200214386\n",
      "Epoch 299 -- loss: 0.18792667984962463\n",
      "Epoch 300 -- loss: 0.1867106407880783\n",
      "Epoch 301 -- loss: 0.1855134516954422\n",
      "Epoch 302 -- loss: 0.18433472514152527\n",
      "Epoch 303 -- loss: 0.18317411839962006\n",
      "Epoch 304 -- loss: 0.18203124403953552\n",
      "Epoch 305 -- loss: 0.18090587854385376\n",
      "Epoch 306 -- loss: 0.17979760468006134\n",
      "Epoch 307 -- loss: 0.1787060797214508\n",
      "Epoch 308 -- loss: 0.17763106524944305\n",
      "Epoch 309 -- loss: 0.17657221853733063\n",
      "Epoch 310 -- loss: 0.17552921175956726\n",
      "Epoch 311 -- loss: 0.17450179159641266\n",
      "Epoch 312 -- loss: 0.17348961532115936\n",
      "Epoch 313 -- loss: 0.17249244451522827\n",
      "Epoch 314 -- loss: 0.17150993645191193\n",
      "Epoch 315 -- loss: 0.17054186761379242\n",
      "Epoch 316 -- loss: 0.16958795487880707\n",
      "Epoch 317 -- loss: 0.16864794492721558\n",
      "Epoch 318 -- loss: 0.16772153973579407\n",
      "Epoch 319 -- loss: 0.16680853068828583\n",
      "Epoch 320 -- loss: 0.16590863466262817\n",
      "Epoch 321 -- loss: 0.1650216281414032\n",
      "Epoch 322 -- loss: 0.164147287607193\n",
      "Epoch 323 -- loss: 0.16328534483909607\n",
      "Epoch 324 -- loss: 0.16243557631969452\n",
      "Epoch 325 -- loss: 0.16159777343273163\n",
      "Epoch 326 -- loss: 0.16077172756195068\n",
      "Epoch 327 -- loss: 0.1599571853876114\n",
      "Epoch 328 -- loss: 0.1591539829969406\n",
      "Epoch 329 -- loss: 0.15836185216903687\n",
      "Epoch 330 -- loss: 0.1575806587934494\n",
      "Epoch 331 -- loss: 0.15681016445159912\n",
      "Epoch 332 -- loss: 0.1560501903295517\n",
      "Epoch 333 -- loss: 0.15530052781105042\n",
      "Epoch 334 -- loss: 0.15456102788448334\n",
      "Epoch 335 -- loss: 0.15383146703243256\n",
      "Epoch 336 -- loss: 0.15311169624328613\n",
      "Epoch 337 -- loss: 0.15240152180194855\n",
      "Epoch 338 -- loss: 0.15170079469680786\n",
      "Epoch 339 -- loss: 0.15100932121276855\n",
      "Epoch 340 -- loss: 0.15032698214054108\n",
      "Epoch 341 -- loss: 0.14965355396270752\n",
      "Epoch 342 -- loss: 0.14898894727230072\n",
      "Epoch 343 -- loss: 0.14833295345306396\n",
      "Epoch 344 -- loss: 0.1476854383945465\n",
      "Epoch 345 -- loss: 0.1470462679862976\n",
      "Epoch 346 -- loss: 0.14641529321670532\n",
      "Epoch 347 -- loss: 0.14579236507415771\n",
      "Epoch 348 -- loss: 0.14517734944820404\n",
      "Epoch 349 -- loss: 0.14457012712955475\n",
      "Epoch 350 -- loss: 0.1439705342054367\n",
      "Epoch 351 -- loss: 0.14337845146656036\n",
      "Epoch 352 -- loss: 0.14279374480247498\n",
      "Epoch 353 -- loss: 0.14221632480621338\n",
      "Epoch 354 -- loss: 0.14164602756500244\n",
      "Epoch 355 -- loss: 0.1410827487707138\n",
      "Epoch 356 -- loss: 0.14052638411521912\n",
      "Epoch 357 -- loss: 0.13997678458690643\n",
      "Epoch 358 -- loss: 0.13943389058113098\n",
      "Epoch 359 -- loss: 0.13889753818511963\n",
      "Epoch 360 -- loss: 0.1383676528930664\n",
      "Epoch 361 -- loss: 0.13784411549568176\n",
      "Epoch 362 -- loss: 0.13732680678367615\n",
      "Epoch 363 -- loss: 0.1368156522512436\n",
      "Epoch 364 -- loss: 0.13631054759025574\n",
      "Epoch 365 -- loss: 0.13581137359142303\n",
      "Epoch 366 -- loss: 0.13531805574893951\n",
      "Epoch 367 -- loss: 0.134830504655838\n",
      "Epoch 368 -- loss: 0.13434861600399017\n",
      "Epoch 369 -- loss: 0.13387228548526764\n",
      "Epoch 370 -- loss: 0.13340145349502563\n",
      "Epoch 371 -- loss: 0.132936030626297\n",
      "Epoch 372 -- loss: 0.13247591257095337\n",
      "Epoch 373 -- loss: 0.1320210099220276\n",
      "Epoch 374 -- loss: 0.13157126307487488\n",
      "Epoch 375 -- loss: 0.13112656772136688\n",
      "Epoch 376 -- loss: 0.1306868940591812\n",
      "Epoch 377 -- loss: 0.13025210797786713\n",
      "Epoch 378 -- loss: 0.12982216477394104\n",
      "Epoch 379 -- loss: 0.12939698994159698\n",
      "Epoch 380 -- loss: 0.1289764940738678\n",
      "Epoch 381 -- loss: 0.1285606473684311\n",
      "Epoch 382 -- loss: 0.12814930081367493\n",
      "Epoch 383 -- loss: 0.1277424693107605\n",
      "Epoch 384 -- loss: 0.12734000384807587\n",
      "Epoch 385 -- loss: 0.12694193422794342\n",
      "Epoch 386 -- loss: 0.12654812633991241\n",
      "Epoch 387 -- loss: 0.12615852057933807\n",
      "Epoch 388 -- loss: 0.12577307224273682\n",
      "Epoch 389 -- loss: 0.12539172172546387\n",
      "Epoch 390 -- loss: 0.12501442432403564\n",
      "Epoch 391 -- loss: 0.1246410608291626\n",
      "Epoch 392 -- loss: 0.12427160888910294\n",
      "Epoch 393 -- loss: 0.12390604615211487\n",
      "Epoch 394 -- loss: 0.12354427576065063\n",
      "Epoch 395 -- loss: 0.12318626046180725\n",
      "Epoch 396 -- loss: 0.12283191084861755\n",
      "Epoch 397 -- loss: 0.12248121947050095\n",
      "Epoch 398 -- loss: 0.12213413417339325\n",
      "Epoch 399 -- loss: 0.1217905730009079\n",
      "Epoch 400 -- loss: 0.12145046144723892\n",
      "Epoch 401 -- loss: 0.12111381441354752\n",
      "Epoch 402 -- loss: 0.1207805722951889\n",
      "Epoch 403 -- loss: 0.12045066803693771\n",
      "Epoch 404 -- loss: 0.12012402713298798\n",
      "Epoch 405 -- loss: 0.11980066448450089\n",
      "Epoch 406 -- loss: 0.11948048323392868\n",
      "Epoch 407 -- loss: 0.11916348338127136\n",
      "Epoch 408 -- loss: 0.11884958297014236\n",
      "Epoch 409 -- loss: 0.1185387670993805\n",
      "Epoch 410 -- loss: 0.11823097616434097\n",
      "Epoch 411 -- loss: 0.11792616546154022\n",
      "Epoch 412 -- loss: 0.11762432008981705\n",
      "Epoch 413 -- loss: 0.11732538044452667\n",
      "Epoch 414 -- loss: 0.11702930182218552\n",
      "Epoch 415 -- loss: 0.11673606187105179\n",
      "Epoch 416 -- loss: 0.11644560843706131\n",
      "Epoch 417 -- loss: 0.11615791916847229\n",
      "Epoch 418 -- loss: 0.11587295681238174\n",
      "Epoch 419 -- loss: 0.1155906617641449\n",
      "Epoch 420 -- loss: 0.11531102657318115\n",
      "Epoch 421 -- loss: 0.11503399163484573\n",
      "Epoch 422 -- loss: 0.11475955694913864\n",
      "Epoch 423 -- loss: 0.11448763310909271\n",
      "Epoch 424 -- loss: 0.11421826481819153\n",
      "Epoch 425 -- loss: 0.11395134031772614\n",
      "Epoch 426 -- loss: 0.11368687450885773\n",
      "Epoch 427 -- loss: 0.11342482268810272\n",
      "Epoch 428 -- loss: 0.11316518485546112\n",
      "Epoch 429 -- loss: 0.11290787160396576\n",
      "Epoch 430 -- loss: 0.11265287548303604\n",
      "Epoch 431 -- loss: 0.11240018904209137\n",
      "Epoch 432 -- loss: 0.11214977502822876\n",
      "Epoch 433 -- loss: 0.11190158128738403\n",
      "Epoch 434 -- loss: 0.11165560781955719\n",
      "Epoch 435 -- loss: 0.11141179502010345\n",
      "Epoch 436 -- loss: 0.11117018014192581\n",
      "Epoch 437 -- loss: 0.11093064397573471\n",
      "Epoch 438 -- loss: 0.11069323867559433\n",
      "Epoch 439 -- loss: 0.1104578971862793\n",
      "Epoch 440 -- loss: 0.11022460460662842\n",
      "Epoch 441 -- loss: 0.1099933385848999\n",
      "Epoch 442 -- loss: 0.10976406931877136\n",
      "Epoch 443 -- loss: 0.1095367819070816\n",
      "Epoch 444 -- loss: 0.10931143909692764\n",
      "Epoch 445 -- loss: 0.10908801108598709\n",
      "Epoch 446 -- loss: 0.10886651277542114\n",
      "Epoch 447 -- loss: 0.10864687711000443\n",
      "Epoch 448 -- loss: 0.10842909663915634\n",
      "Epoch 449 -- loss: 0.10821317136287689\n",
      "Epoch 450 -- loss: 0.10799902677536011\n",
      "Epoch 451 -- loss: 0.10778669267892838\n",
      "Epoch 452 -- loss: 0.10757613182067871\n",
      "Epoch 453 -- loss: 0.10736731439828873\n",
      "Epoch 454 -- loss: 0.10716023296117783\n",
      "Epoch 455 -- loss: 0.10695487260818481\n",
      "Epoch 456 -- loss: 0.10675116628408432\n",
      "Epoch 457 -- loss: 0.10654914379119873\n",
      "Epoch 458 -- loss: 0.10634876787662506\n",
      "Epoch 459 -- loss: 0.10615003854036331\n",
      "Epoch 460 -- loss: 0.10595289617776871\n",
      "Epoch 461 -- loss: 0.10575735569000244\n",
      "Epoch 462 -- loss: 0.10556340962648392\n",
      "Epoch 463 -- loss: 0.10537097603082657\n",
      "Epoch 464 -- loss: 0.10518012195825577\n",
      "Epoch 465 -- loss: 0.10499075055122375\n",
      "Epoch 466 -- loss: 0.1048029214143753\n",
      "Epoch 467 -- loss: 0.10461655259132385\n",
      "Epoch 468 -- loss: 0.10443165898323059\n",
      "Epoch 469 -- loss: 0.10424821078777313\n",
      "Epoch 470 -- loss: 0.10406619310379028\n",
      "Epoch 471 -- loss: 0.10388559848070145\n",
      "Epoch 472 -- loss: 0.10370641946792603\n",
      "Epoch 473 -- loss: 0.10352862626314163\n",
      "Epoch 474 -- loss: 0.10335218906402588\n",
      "Epoch 475 -- loss: 0.10317712277173996\n",
      "Epoch 476 -- loss: 0.10300339013338089\n",
      "Epoch 477 -- loss: 0.10283099859952927\n",
      "Epoch 478 -- loss: 0.1026599109172821\n",
      "Epoch 479 -- loss: 0.10249010473489761\n",
      "Epoch 480 -- loss: 0.10232159495353699\n",
      "Epoch 481 -- loss: 0.10215435922145844\n",
      "Epoch 482 -- loss: 0.10198839008808136\n",
      "Epoch 483 -- loss: 0.10182364284992218\n",
      "Epoch 484 -- loss: 0.10166012495756149\n",
      "Epoch 485 -- loss: 0.1014978289604187\n",
      "Epoch 486 -- loss: 0.10133672505617142\n",
      "Epoch 487 -- loss: 0.10117682069540024\n",
      "Epoch 488 -- loss: 0.10101807862520218\n",
      "Epoch 489 -- loss: 0.10086052119731903\n",
      "Epoch 490 -- loss: 0.10070409625768661\n",
      "Epoch 491 -- loss: 0.10054881125688553\n",
      "Epoch 492 -- loss: 0.10039465129375458\n",
      "Epoch 493 -- loss: 0.10024161636829376\n",
      "Epoch 494 -- loss: 0.1000896692276001\n",
      "Epoch 495 -- loss: 0.09993883222341537\n",
      "Epoch 496 -- loss: 0.09978906810283661\n",
      "Epoch 497 -- loss: 0.09964035451412201\n",
      "Epoch 498 -- loss: 0.09949272125959396\n",
      "Epoch 499 -- loss: 0.0993461161851883\n",
      "Epoch 500 -- loss: 0.0992005467414856\n",
      "Epoch 501 -- loss: 0.09905600547790527\n",
      "Epoch 502 -- loss: 0.09891247004270554\n",
      "Epoch 503 -- loss: 0.09876996278762817\n",
      "Epoch 504 -- loss: 0.09862841665744781\n",
      "Epoch 505 -- loss: 0.09848786890506744\n",
      "Epoch 506 -- loss: 0.09834828227758408\n",
      "Epoch 507 -- loss: 0.09820965677499771\n",
      "Epoch 508 -- loss: 0.09807199239730835\n",
      "Epoch 509 -- loss: 0.0979352667927742\n",
      "Epoch 510 -- loss: 0.09779947251081467\n",
      "Epoch 511 -- loss: 0.09766460955142975\n",
      "Epoch 512 -- loss: 0.09753066301345825\n",
      "Epoch 513 -- loss: 0.09739760309457779\n",
      "Epoch 514 -- loss: 0.09726543724536896\n",
      "Epoch 515 -- loss: 0.09713416546583176\n",
      "Epoch 516 -- loss: 0.09700377285480499\n",
      "Epoch 517 -- loss: 0.09687422960996628\n",
      "Epoch 518 -- loss: 0.0967455804347992\n",
      "Epoch 519 -- loss: 0.09661775082349777\n",
      "Epoch 520 -- loss: 0.096490778028965\n",
      "Epoch 521 -- loss: 0.09636463969945908\n",
      "Epoch 522 -- loss: 0.09623930603265762\n",
      "Epoch 523 -- loss: 0.09611481428146362\n",
      "Epoch 524 -- loss: 0.0959911122918129\n",
      "Epoch 525 -- loss: 0.09586823731660843\n",
      "Epoch 526 -- loss: 0.09574613720178604\n",
      "Epoch 527 -- loss: 0.09562482684850693\n",
      "Epoch 528 -- loss: 0.09550430625677109\n",
      "Epoch 529 -- loss: 0.09538454562425613\n",
      "Epoch 530 -- loss: 0.09526554495096207\n",
      "Epoch 531 -- loss: 0.09514728933572769\n",
      "Epoch 532 -- loss: 0.0950297936797142\n",
      "Epoch 533 -- loss: 0.0949130430817604\n",
      "Epoch 534 -- loss: 0.09479701519012451\n",
      "Epoch 535 -- loss: 0.09468171745538712\n",
      "Epoch 536 -- loss: 0.09456714242696762\n",
      "Epoch 537 -- loss: 0.09445326775312424\n",
      "Epoch 538 -- loss: 0.09434012323617935\n",
      "Epoch 539 -- loss: 0.09422764927148819\n",
      "Epoch 540 -- loss: 0.09411586821079254\n",
      "Epoch 541 -- loss: 0.094004787504673\n",
      "Epoch 542 -- loss: 0.09389438480138779\n",
      "Epoch 543 -- loss: 0.09378465265035629\n",
      "Epoch 544 -- loss: 0.09367558360099792\n",
      "Epoch 545 -- loss: 0.09356717020273209\n",
      "Epoch 546 -- loss: 0.09345942735671997\n",
      "Epoch 547 -- loss: 0.09335232526063919\n",
      "Epoch 548 -- loss: 0.09324584156274796\n",
      "Epoch 549 -- loss: 0.09314002096652985\n",
      "Epoch 550 -- loss: 0.09303481876850128\n",
      "Epoch 551 -- loss: 0.09293024241924286\n",
      "Epoch 552 -- loss: 0.09282626956701279\n",
      "Epoch 553 -- loss: 0.09272292256355286\n",
      "Epoch 554 -- loss: 0.09262017905712128\n",
      "Epoch 555 -- loss: 0.09251803904771805\n",
      "Epoch 556 -- loss: 0.09241648763418198\n",
      "Epoch 557 -- loss: 0.09231553226709366\n",
      "Epoch 558 -- loss: 0.0922151580452919\n",
      "Epoch 559 -- loss: 0.09211535006761551\n",
      "Epoch 560 -- loss: 0.09201613813638687\n",
      "Epoch 561 -- loss: 0.0919174775481224\n",
      "Epoch 562 -- loss: 0.0918193906545639\n",
      "Epoch 563 -- loss: 0.09172184765338898\n",
      "Epoch 564 -- loss: 0.09162486344575882\n",
      "Epoch 565 -- loss: 0.09152843803167343\n",
      "Epoch 566 -- loss: 0.09143254160881042\n",
      "Epoch 567 -- loss: 0.0913371741771698\n",
      "Epoch 568 -- loss: 0.09124235808849335\n",
      "Epoch 569 -- loss: 0.09114807099103928\n",
      "Epoch 570 -- loss: 0.0910542830824852\n",
      "Epoch 571 -- loss: 0.0909610390663147\n",
      "Epoch 572 -- loss: 0.09086830168962479\n",
      "Epoch 573 -- loss: 0.09077607840299606\n",
      "Epoch 574 -- loss: 0.09068434685468674\n",
      "Epoch 575 -- loss: 0.0905931293964386\n",
      "Epoch 576 -- loss: 0.09050239622592926\n",
      "Epoch 577 -- loss: 0.09041215479373932\n",
      "Epoch 578 -- loss: 0.09032241255044937\n",
      "Epoch 579 -- loss: 0.09023316204547882\n",
      "Epoch 580 -- loss: 0.09014435857534409\n",
      "Epoch 581 -- loss: 0.09005605429410934\n",
      "Epoch 582 -- loss: 0.08996820449829102\n",
      "Epoch 583 -- loss: 0.08988084644079208\n",
      "Epoch 584 -- loss: 0.08979392051696777\n",
      "Epoch 585 -- loss: 0.08970746397972107\n",
      "Epoch 586 -- loss: 0.08962146192789078\n",
      "Epoch 587 -- loss: 0.0895359143614769\n",
      "Epoch 588 -- loss: 0.08945079892873764\n",
      "Epoch 589 -- loss: 0.08936614543199539\n",
      "Epoch 590 -- loss: 0.08928190916776657\n",
      "Epoch 591 -- loss: 0.08919812738895416\n",
      "Epoch 592 -- loss: 0.08911477029323578\n",
      "Epoch 593 -- loss: 0.08903184533119202\n",
      "Epoch 594 -- loss: 0.08894932270050049\n",
      "Epoch 595 -- loss: 0.08886723220348358\n",
      "Epoch 596 -- loss: 0.0887855589389801\n",
      "Epoch 597 -- loss: 0.08870429545640945\n",
      "Epoch 598 -- loss: 0.08862345665693283\n",
      "Epoch 599 -- loss: 0.08854302018880844\n",
      "Epoch 600 -- loss: 0.08846297115087509\n",
      "Epoch 601 -- loss: 0.08838334679603577\n",
      "Epoch 602 -- loss: 0.08830408751964569\n",
      "Epoch 603 -- loss: 0.08822523802518845\n",
      "Epoch 604 -- loss: 0.08814676105976105\n",
      "Epoch 605 -- loss: 0.08806870132684708\n",
      "Epoch 606 -- loss: 0.08799100667238235\n",
      "Epoch 607 -- loss: 0.08791369944810867\n",
      "Epoch 608 -- loss: 0.08783675730228424\n",
      "Epoch 609 -- loss: 0.08776019513607025\n",
      "Epoch 610 -- loss: 0.08768399059772491\n",
      "Epoch 611 -- loss: 0.08760816603899002\n",
      "Epoch 612 -- loss: 0.08753270655870438\n",
      "Epoch 613 -- loss: 0.08745761960744858\n",
      "Epoch 614 -- loss: 0.08738286048173904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 615 -- loss: 0.08730847388505936\n",
      "Epoch 616 -- loss: 0.08723444491624832\n",
      "Epoch 617 -- loss: 0.08716075122356415\n",
      "Epoch 618 -- loss: 0.08708742260932922\n",
      "Epoch 619 -- loss: 0.08701442927122116\n",
      "Epoch 620 -- loss: 0.08694177120923996\n",
      "Epoch 621 -- loss: 0.08686946332454681\n",
      "Epoch 622 -- loss: 0.08679747581481934\n",
      "Epoch 623 -- loss: 0.08672583848237991\n",
      "Epoch 624 -- loss: 0.08665452897548676\n",
      "Epoch 625 -- loss: 0.08658353984355927\n",
      "Epoch 626 -- loss: 0.08651286363601685\n",
      "Epoch 627 -- loss: 0.08644253015518188\n",
      "Epoch 628 -- loss: 0.086372509598732\n",
      "Epoch 629 -- loss: 0.08630280941724777\n",
      "Epoch 630 -- loss: 0.08623341470956802\n",
      "Epoch 631 -- loss: 0.08616436272859573\n",
      "Epoch 632 -- loss: 0.08609557896852493\n",
      "Epoch 633 -- loss: 0.0860271230340004\n",
      "Epoch 634 -- loss: 0.08595898002386093\n",
      "Epoch 635 -- loss: 0.08589112758636475\n",
      "Epoch 636 -- loss: 0.08582356572151184\n",
      "Epoch 637 -- loss: 0.0857563316822052\n",
      "Epoch 638 -- loss: 0.08568936586380005\n",
      "Epoch 639 -- loss: 0.08562270551919937\n",
      "Epoch 640 -- loss: 0.08555633574724197\n",
      "Epoch 641 -- loss: 0.08549025654792786\n",
      "Epoch 642 -- loss: 0.08542446047067642\n",
      "Epoch 643 -- loss: 0.08535894006490707\n",
      "Epoch 644 -- loss: 0.0852937176823616\n",
      "Epoch 645 -- loss: 0.08522877842187881\n",
      "Epoch 646 -- loss: 0.08516411483287811\n",
      "Epoch 647 -- loss: 0.0850997120141983\n",
      "Epoch 648 -- loss: 0.08503560721874237\n",
      "Epoch 649 -- loss: 0.08497174084186554\n",
      "Epoch 650 -- loss: 0.08490816503763199\n",
      "Epoch 651 -- loss: 0.08484486490488052\n",
      "Epoch 652 -- loss: 0.08478181809186935\n",
      "Epoch 653 -- loss: 0.08471903949975967\n",
      "Epoch 654 -- loss: 0.08465652167797089\n",
      "Epoch 655 -- loss: 0.08459427207708359\n",
      "Epoch 656 -- loss: 0.0845322534441948\n",
      "Epoch 657 -- loss: 0.08447051793336868\n",
      "Epoch 658 -- loss: 0.08440902084112167\n",
      "Epoch 659 -- loss: 0.08434777706861496\n",
      "Epoch 660 -- loss: 0.08428677916526794\n",
      "Epoch 661 -- loss: 0.08422604948282242\n",
      "Epoch 662 -- loss: 0.0841655507683754\n",
      "Epoch 663 -- loss: 0.08410530537366867\n",
      "Epoch 664 -- loss: 0.08404529094696045\n",
      "Epoch 665 -- loss: 0.08398552983999252\n",
      "Epoch 666 -- loss: 0.0839259997010231\n",
      "Epoch 667 -- loss: 0.08386671543121338\n",
      "Epoch 668 -- loss: 0.08380766957998276\n",
      "Epoch 669 -- loss: 0.08374884724617004\n",
      "Epoch 670 -- loss: 0.08369025588035583\n",
      "Epoch 671 -- loss: 0.08363192528486252\n",
      "Epoch 672 -- loss: 0.08357378840446472\n",
      "Epoch 673 -- loss: 0.08351588994264603\n",
      "Epoch 674 -- loss: 0.08345821499824524\n",
      "Epoch 675 -- loss: 0.08340077102184296\n",
      "Epoch 676 -- loss: 0.08334354311227798\n",
      "Epoch 677 -- loss: 0.08328655362129211\n",
      "Epoch 678 -- loss: 0.08322977274656296\n",
      "Epoch 679 -- loss: 0.08317320048809052\n",
      "Epoch 680 -- loss: 0.08311685919761658\n",
      "Epoch 681 -- loss: 0.08306072652339935\n",
      "Epoch 682 -- loss: 0.08300479501485825\n",
      "Epoch 683 -- loss: 0.08294910192489624\n",
      "Epoch 684 -- loss: 0.08289359509944916\n",
      "Epoch 685 -- loss: 0.08283831179141998\n",
      "Epoch 686 -- loss: 0.08278323709964752\n",
      "Epoch 687 -- loss: 0.08272835612297058\n",
      "Epoch 688 -- loss: 0.08267369121313095\n",
      "Epoch 689 -- loss: 0.08261923491954803\n",
      "Epoch 690 -- loss: 0.08256496489048004\n",
      "Epoch 691 -- loss: 0.08251090347766876\n",
      "Epoch 692 -- loss: 0.0824570283293724\n",
      "Epoch 693 -- loss: 0.08240336924791336\n",
      "Epoch 694 -- loss: 0.08234990388154984\n",
      "Epoch 695 -- loss: 0.08229662477970123\n",
      "Epoch 696 -- loss: 0.08224355429410934\n",
      "Epoch 697 -- loss: 0.08219067007303238\n",
      "Epoch 698 -- loss: 0.08213795721530914\n",
      "Epoch 699 -- loss: 0.08208545297384262\n",
      "Epoch 700 -- loss: 0.08203314244747162\n",
      "Epoch 701 -- loss: 0.08198100328445435\n",
      "Epoch 702 -- loss: 0.08192906528711319\n",
      "Epoch 703 -- loss: 0.08187730610370636\n",
      "Epoch 704 -- loss: 0.08182573318481445\n",
      "Epoch 705 -- loss: 0.08177433162927628\n",
      "Epoch 706 -- loss: 0.08172312378883362\n",
      "Epoch 707 -- loss: 0.08167209476232529\n",
      "Epoch 708 -- loss: 0.08162123709917068\n",
      "Epoch 709 -- loss: 0.081570565700531\n",
      "Epoch 710 -- loss: 0.08152007311582565\n",
      "Epoch 711 -- loss: 0.08146974444389343\n",
      "Epoch 712 -- loss: 0.08141960203647614\n",
      "Epoch 713 -- loss: 0.08136960864067078\n",
      "Epoch 714 -- loss: 0.08131981641054153\n",
      "Epoch 715 -- loss: 0.08127018809318542\n",
      "Epoch 716 -- loss: 0.08122072368860245\n",
      "Epoch 717 -- loss: 0.0811714231967926\n",
      "Epoch 718 -- loss: 0.08112230896949768\n",
      "Epoch 719 -- loss: 0.0810733288526535\n",
      "Epoch 720 -- loss: 0.08102454245090485\n",
      "Epoch 721 -- loss: 0.08097591251134872\n",
      "Epoch 722 -- loss: 0.08092746138572693\n",
      "Epoch 723 -- loss: 0.08087915927171707\n",
      "Epoch 724 -- loss: 0.08083100616931915\n",
      "Epoch 725 -- loss: 0.08078300952911377\n",
      "Epoch 726 -- loss: 0.08073519915342331\n",
      "Epoch 727 -- loss: 0.08068753778934479\n",
      "Epoch 728 -- loss: 0.0806400254368782\n",
      "Epoch 729 -- loss: 0.08059266954660416\n",
      "Epoch 730 -- loss: 0.08054548501968384\n",
      "Epoch 731 -- loss: 0.08049844205379486\n",
      "Epoch 732 -- loss: 0.08045154809951782\n",
      "Epoch 733 -- loss: 0.08040482550859451\n",
      "Epoch 734 -- loss: 0.08035822957754135\n",
      "Epoch 735 -- loss: 0.08031179755926132\n",
      "Epoch 736 -- loss: 0.08026549965143204\n",
      "Epoch 737 -- loss: 0.08021938800811768\n",
      "Epoch 738 -- loss: 0.08017338812351227\n",
      "Epoch 739 -- loss: 0.0801275447010994\n",
      "Epoch 740 -- loss: 0.08008184283971786\n",
      "Epoch 741 -- loss: 0.08003629744052887\n",
      "Epoch 742 -- loss: 0.07999088615179062\n",
      "Epoch 743 -- loss: 0.0799456387758255\n",
      "Epoch 744 -- loss: 0.07990051060914993\n",
      "Epoch 745 -- loss: 0.0798555538058281\n",
      "Epoch 746 -- loss: 0.07981069386005402\n",
      "Epoch 747 -- loss: 0.07976600527763367\n",
      "Epoch 748 -- loss: 0.07972145825624466\n",
      "Epoch 749 -- loss: 0.0796770453453064\n",
      "Epoch 750 -- loss: 0.07963274419307709\n",
      "Epoch 751 -- loss: 0.07958861440420151\n",
      "Epoch 752 -- loss: 0.07954458892345428\n",
      "Epoch 753 -- loss: 0.0795007273554802\n",
      "Epoch 754 -- loss: 0.07945697009563446\n",
      "Epoch 755 -- loss: 0.07941339164972305\n",
      "Epoch 756 -- loss: 0.0793699100613594\n",
      "Epoch 757 -- loss: 0.0793265551328659\n",
      "Epoch 758 -- loss: 0.07928333431482315\n",
      "Epoch 759 -- loss: 0.07924028486013412\n",
      "Epoch 760 -- loss: 0.07919732481241226\n",
      "Epoch 761 -- loss: 0.07915450632572174\n",
      "Epoch 762 -- loss: 0.07911180704832077\n",
      "Epoch 763 -- loss: 0.07906924933195114\n",
      "Epoch 764 -- loss: 0.07902681082487106\n",
      "Epoch 765 -- loss: 0.07898450642824173\n",
      "Epoch 766 -- loss: 0.07894229888916016\n",
      "Epoch 767 -- loss: 0.07890024036169052\n",
      "Epoch 768 -- loss: 0.07885830104351044\n",
      "Epoch 769 -- loss: 0.0788164958357811\n",
      "Epoch 770 -- loss: 0.07877480238676071\n",
      "Epoch 771 -- loss: 0.07873322814702988\n",
      "Epoch 772 -- loss: 0.07869178056716919\n",
      "Epoch 773 -- loss: 0.07865045219659805\n",
      "Epoch 774 -- loss: 0.07860923558473587\n",
      "Epoch 775 -- loss: 0.07856816053390503\n",
      "Epoch 776 -- loss: 0.07852717489004135\n",
      "Epoch 777 -- loss: 0.07848634570837021\n",
      "Epoch 778 -- loss: 0.07844557613134384\n",
      "Epoch 779 -- loss: 0.0784049853682518\n",
      "Epoch 780 -- loss: 0.07836446166038513\n",
      "Epoch 781 -- loss: 0.07832407206296921\n",
      "Epoch 782 -- loss: 0.07828381657600403\n",
      "Epoch 783 -- loss: 0.07824365049600601\n",
      "Epoch 784 -- loss: 0.07820359617471695\n",
      "Epoch 785 -- loss: 0.07816366851329803\n",
      "Epoch 786 -- loss: 0.07812383770942688\n",
      "Epoch 787 -- loss: 0.07808411866426468\n",
      "Epoch 788 -- loss: 0.07804452627897263\n",
      "Epoch 789 -- loss: 0.07800503820180893\n",
      "Epoch 790 -- loss: 0.07796566188335419\n",
      "Epoch 791 -- loss: 0.0779263973236084\n",
      "Epoch 792 -- loss: 0.07788722217082977\n",
      "Epoch 793 -- loss: 0.0778481587767601\n",
      "Epoch 794 -- loss: 0.07780922949314117\n",
      "Epoch 795 -- loss: 0.07777038216590881\n",
      "Epoch 796 -- loss: 0.07773163914680481\n",
      "Epoch 797 -- loss: 0.07769301533699036\n",
      "Epoch 798 -- loss: 0.07765449583530426\n",
      "Epoch 799 -- loss: 0.07761607319116592\n",
      "Epoch 800 -- loss: 0.07757776230573654\n",
      "Epoch 801 -- loss: 0.07753955572843552\n",
      "Epoch 802 -- loss: 0.07750143855810165\n",
      "Epoch 803 -- loss: 0.07746344804763794\n",
      "Epoch 804 -- loss: 0.07742554694414139\n",
      "Epoch 805 -- loss: 0.0773877426981926\n",
      "Epoch 806 -- loss: 0.07735004276037216\n",
      "Epoch 807 -- loss: 0.07731243222951889\n",
      "Epoch 808 -- loss: 0.07727493345737457\n",
      "Epoch 809 -- loss: 0.07723753899335861\n",
      "Epoch 810 -- loss: 0.07720023393630981\n",
      "Epoch 811 -- loss: 0.07716303318738937\n",
      "Epoch 812 -- loss: 0.07712593674659729\n",
      "Epoch 813 -- loss: 0.07708892226219177\n",
      "Epoch 814 -- loss: 0.07705201953649521\n",
      "Epoch 815 -- loss: 0.07701519876718521\n",
      "Epoch 816 -- loss: 0.07697846740484238\n",
      "Epoch 817 -- loss: 0.0769418478012085\n",
      "Epoch 818 -- loss: 0.07690531760454178\n",
      "Epoch 819 -- loss: 0.07686888426542282\n",
      "Epoch 820 -- loss: 0.07683256268501282\n",
      "Epoch 821 -- loss: 0.07679631561040878\n",
      "Epoch 822 -- loss: 0.07676015049219131\n",
      "Epoch 823 -- loss: 0.0767240971326828\n",
      "Epoch 824 -- loss: 0.07668812572956085\n",
      "Epoch 825 -- loss: 0.07665222883224487\n",
      "Epoch 826 -- loss: 0.07661647349596024\n",
      "Epoch 827 -- loss: 0.07658077031373978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 828 -- loss: 0.07654516398906708\n",
      "Epoch 829 -- loss: 0.07650964707136154\n",
      "Epoch 830 -- loss: 0.07647421956062317\n",
      "Epoch 831 -- loss: 0.07643888890743256\n",
      "Epoch 832 -- loss: 0.07640364021062851\n",
      "Epoch 833 -- loss: 0.07636848092079163\n",
      "Epoch 834 -- loss: 0.0763334110379219\n",
      "Epoch 835 -- loss: 0.07629842311143875\n",
      "Epoch 836 -- loss: 0.07626352459192276\n",
      "Epoch 837 -- loss: 0.07622873038053513\n",
      "Epoch 838 -- loss: 0.07619399577379227\n",
      "Epoch 839 -- loss: 0.07615935057401657\n",
      "Epoch 840 -- loss: 0.07612480223178864\n",
      "Epoch 841 -- loss: 0.07609032839536667\n",
      "Epoch 842 -- loss: 0.07605595141649246\n",
      "Epoch 843 -- loss: 0.07602165639400482\n",
      "Epoch 844 -- loss: 0.07598742842674255\n",
      "Epoch 845 -- loss: 0.07595330476760864\n",
      "Epoch 846 -- loss: 0.0759192556142807\n",
      "Epoch 847 -- loss: 0.07588529586791992\n",
      "Epoch 848 -- loss: 0.07585140317678452\n",
      "Epoch 849 -- loss: 0.07581759989261627\n",
      "Epoch 850 -- loss: 0.07578388601541519\n",
      "Epoch 851 -- loss: 0.07575025409460068\n",
      "Epoch 852 -- loss: 0.07571669667959213\n",
      "Epoch 853 -- loss: 0.07568320631980896\n",
      "Epoch 854 -- loss: 0.07564981281757355\n",
      "Epoch 855 -- loss: 0.0756165012717247\n",
      "Epoch 856 -- loss: 0.07558324933052063\n",
      "Epoch 857 -- loss: 0.07555008679628372\n",
      "Epoch 858 -- loss: 0.07551700621843338\n",
      "Epoch 859 -- loss: 0.07548400014638901\n",
      "Epoch 860 -- loss: 0.0754510685801506\n",
      "Epoch 861 -- loss: 0.07541822642087936\n",
      "Epoch 862 -- loss: 0.07538545876741409\n",
      "Epoch 863 -- loss: 0.0753527581691742\n",
      "Epoch 864 -- loss: 0.07532014697790146\n",
      "Epoch 865 -- loss: 0.0752875953912735\n",
      "Epoch 866 -- loss: 0.0752551332116127\n",
      "Epoch 867 -- loss: 0.07522273808717728\n",
      "Epoch 868 -- loss: 0.07519042491912842\n",
      "Epoch 869 -- loss: 0.07515818625688553\n",
      "Epoch 870 -- loss: 0.07512601464986801\n",
      "Epoch 871 -- loss: 0.07509392499923706\n",
      "Epoch 872 -- loss: 0.07506191730499268\n",
      "Epoch 873 -- loss: 0.07502996921539307\n",
      "Epoch 874 -- loss: 0.07499811053276062\n",
      "Epoch 875 -- loss: 0.07496628910303116\n",
      "Epoch 876 -- loss: 0.07493456453084946\n",
      "Epoch 877 -- loss: 0.07490291446447372\n",
      "Epoch 878 -- loss: 0.07487132400274277\n",
      "Epoch 879 -- loss: 0.07483981549739838\n",
      "Epoch 880 -- loss: 0.07480837404727936\n",
      "Epoch 881 -- loss: 0.07477699965238571\n",
      "Epoch 882 -- loss: 0.07474569976329803\n",
      "Epoch 883 -- loss: 0.07471447438001633\n",
      "Epoch 884 -- loss: 0.0746833011507988\n",
      "Epoch 885 -- loss: 0.07465222477912903\n",
      "Epoch 886 -- loss: 0.07462121546268463\n",
      "Epoch 887 -- loss: 0.07459025084972382\n",
      "Epoch 888 -- loss: 0.07455937564373016\n",
      "Epoch 889 -- loss: 0.07452857494354248\n",
      "Epoch 890 -- loss: 0.07449781894683838\n",
      "Epoch 891 -- loss: 0.07446713745594025\n",
      "Epoch 892 -- loss: 0.07443653792142868\n",
      "Epoch 893 -- loss: 0.07440601289272308\n",
      "Epoch 894 -- loss: 0.07437554001808167\n",
      "Epoch 895 -- loss: 0.07434512674808502\n",
      "Epoch 896 -- loss: 0.07431479543447495\n",
      "Epoch 897 -- loss: 0.07428452372550964\n",
      "Epoch 898 -- loss: 0.07425432652235031\n",
      "Epoch 899 -- loss: 0.07422416657209396\n",
      "Epoch 900 -- loss: 0.07419407367706299\n",
      "Epoch 901 -- loss: 0.07416407763957977\n",
      "Epoch 902 -- loss: 0.07413414120674133\n",
      "Epoch 903 -- loss: 0.07410425692796707\n",
      "Epoch 904 -- loss: 0.07407443225383759\n",
      "Epoch 905 -- loss: 0.07404467463493347\n",
      "Epoch 906 -- loss: 0.07401499897241592\n",
      "Epoch 907 -- loss: 0.07398537546396255\n",
      "Epoch 908 -- loss: 0.07395581901073456\n",
      "Epoch 909 -- loss: 0.07392630726099014\n",
      "Epoch 910 -- loss: 0.0738968774676323\n",
      "Epoch 911 -- loss: 0.07386749982833862\n",
      "Epoch 912 -- loss: 0.07383818924427032\n",
      "Epoch 913 -- loss: 0.073808953166008\n",
      "Epoch 914 -- loss: 0.07377977669239044\n",
      "Epoch 915 -- loss: 0.07375063002109528\n",
      "Epoch 916 -- loss: 0.07372158020734787\n",
      "Epoch 917 -- loss: 0.07369257509708405\n",
      "Epoch 918 -- loss: 0.0736636370420456\n",
      "Epoch 919 -- loss: 0.07363475114107132\n",
      "Epoch 920 -- loss: 0.07360593974590302\n",
      "Epoch 921 -- loss: 0.07357717305421829\n",
      "Epoch 922 -- loss: 0.07354847341775894\n",
      "Epoch 923 -- loss: 0.07351984828710556\n",
      "Epoch 924 -- loss: 0.07349126040935516\n",
      "Epoch 925 -- loss: 0.07346275448799133\n",
      "Epoch 926 -- loss: 0.07343427836894989\n",
      "Epoch 927 -- loss: 0.07340589165687561\n",
      "Epoch 928 -- loss: 0.07337754219770432\n",
      "Epoch 929 -- loss: 0.0733492523431778\n",
      "Epoch 930 -- loss: 0.07332102209329605\n",
      "Epoch 931 -- loss: 0.07329285144805908\n",
      "Epoch 932 -- loss: 0.07326473295688629\n",
      "Epoch 933 -- loss: 0.07323669642210007\n",
      "Epoch 934 -- loss: 0.07320868968963623\n",
      "Epoch 935 -- loss: 0.07318076491355896\n",
      "Epoch 936 -- loss: 0.07315288484096527\n",
      "Epoch 937 -- loss: 0.07312504202127457\n",
      "Epoch 938 -- loss: 0.07309728115797043\n",
      "Epoch 939 -- loss: 0.07306957244873047\n",
      "Epoch 940 -- loss: 0.07304190844297409\n",
      "Epoch 941 -- loss: 0.07301429659128189\n",
      "Epoch 942 -- loss: 0.07298676669597626\n",
      "Epoch 943 -- loss: 0.07295926660299301\n",
      "Epoch 944 -- loss: 0.07293184101581573\n",
      "Epoch 945 -- loss: 0.07290443778038025\n",
      "Epoch 946 -- loss: 0.07287711650133133\n",
      "Epoch 947 -- loss: 0.07284985482692719\n",
      "Epoch 948 -- loss: 0.07282264530658722\n",
      "Epoch 949 -- loss: 0.07279548794031143\n",
      "Epoch 950 -- loss: 0.07276836037635803\n",
      "Epoch 951 -- loss: 0.07274129986763\n",
      "Epoch 952 -- loss: 0.07271430641412735\n",
      "Epoch 953 -- loss: 0.07268736511468887\n",
      "Epoch 954 -- loss: 0.07266045361757278\n",
      "Epoch 955 -- loss: 0.07263362407684326\n",
      "Epoch 956 -- loss: 0.07260683923959732\n",
      "Epoch 957 -- loss: 0.07258008420467377\n",
      "Epoch 958 -- loss: 0.07255341112613678\n",
      "Epoch 959 -- loss: 0.07252678275108337\n",
      "Epoch 960 -- loss: 0.07250019162893295\n",
      "Epoch 961 -- loss: 0.0724736750125885\n",
      "Epoch 962 -- loss: 0.07244720309972763\n",
      "Epoch 963 -- loss: 0.07242077589035034\n",
      "Epoch 964 -- loss: 0.07239439338445663\n",
      "Epoch 965 -- loss: 0.0723680704832077\n",
      "Epoch 966 -- loss: 0.07234180718660355\n",
      "Epoch 967 -- loss: 0.07231558114290237\n",
      "Epoch 968 -- loss: 0.07228941470384598\n",
      "Epoch 969 -- loss: 0.07226330041885376\n",
      "Epoch 970 -- loss: 0.07223720848560333\n",
      "Epoch 971 -- loss: 0.07221119105815887\n",
      "Epoch 972 -- loss: 0.0721852108836174\n",
      "Epoch 973 -- loss: 0.0721593126654625\n",
      "Epoch 974 -- loss: 0.07213341444730759\n",
      "Epoch 975 -- loss: 0.07210761308670044\n",
      "Epoch 976 -- loss: 0.07208183407783508\n",
      "Epoch 977 -- loss: 0.0720561072230339\n",
      "Epoch 978 -- loss: 0.0720304474234581\n",
      "Epoch 979 -- loss: 0.07200481742620468\n",
      "Epoch 980 -- loss: 0.07197923958301544\n",
      "Epoch 981 -- loss: 0.07195369899272919\n",
      "Epoch 982 -- loss: 0.07192821055650711\n",
      "Epoch 983 -- loss: 0.07190277427434921\n",
      "Epoch 984 -- loss: 0.07187740504741669\n",
      "Epoch 985 -- loss: 0.07185206562280655\n",
      "Epoch 986 -- loss: 0.0718267634510994\n",
      "Epoch 987 -- loss: 0.07180152088403702\n",
      "Epoch 988 -- loss: 0.07177632302045822\n",
      "Epoch 989 -- loss: 0.071751169860363\n",
      "Epoch 990 -- loss: 0.07172608375549316\n",
      "Epoch 991 -- loss: 0.07170101255178452\n",
      "Epoch 992 -- loss: 0.07167600095272064\n",
      "Epoch 993 -- loss: 0.07165103405714035\n",
      "Epoch 994 -- loss: 0.07162613421678543\n",
      "Epoch 995 -- loss: 0.07160124182701111\n",
      "Epoch 996 -- loss: 0.07157642394304276\n",
      "Epoch 997 -- loss: 0.07155164331197739\n",
      "Epoch 998 -- loss: 0.0715269073843956\n",
      "Epoch 999 -- loss: 0.0715022087097168\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    #zeroing gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #shuffling dataset\n",
    "    idx = np.random.permutation(X.shape[0])\n",
    "    X = X[idx]\n",
    "    y = y[idx]\n",
    "    \n",
    "    out = net.forward(X)\n",
    "    loss = criterion(out, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {i} -- loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_test(f, mean, std):\n",
    "    df = pd.read_csv(f, header=None, index_col=0)\n",
    "    labels = df.pop(1).eq('M').mul(1)\n",
    "    data = (df - mean) / std\n",
    "    X, y = data.values.astype(float), labels.values.astype(int)\n",
    "    y = y.reshape(-1, 1)\n",
    "    y = np.array([[0, 1] if x else [1, 0] for x in y])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = fetch_test(\"data_test.csv\", mean, std)\n",
    "X_test, y_test = torch.from_numpy(X_test).float(), torch.from_numpy(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.033865779638290405\n"
     ]
    }
   ],
   "source": [
    "out = net.forward(X_test)\n",
    "loss = criterion(out, y_test)\n",
    "print(\"Test loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NeuralNet import NeuralNet, Dense, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = NeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN.append(Dense(20, 30))\n",
    "NN.append(Dense(10, 20))\n",
    "NN.append(Dense(2, 10, activation=softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, _ = NN.train(X.numpy(), y.numpy(), epoch=1000, rate=0.1, batch=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06668480485677719\n"
     ]
    }
   ],
   "source": [
    "#calculate loss using pytorch neural network\n",
    "out = NN.forward(X_test.numpy())\n",
    "loss = criterion(torch.from_numpy(out).float(), y_test)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.066684806953812\n"
     ]
    }
   ],
   "source": [
    "#calculate loss using my code\n",
    "print(NN.loss(X_test.numpy(), y_test.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
